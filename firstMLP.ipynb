{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d8597f-bcbb-4447-a675-dd2d6ff585f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cf785195-471e-4ce8-895d-26dae24494dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relU(vector): \n",
    "    ln = len(vector) #do in place modification\n",
    "    for i in range(ln):\n",
    "        if vector[i] < 0:\n",
    "            vector[i] = 0\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7281802-d5ec-417a-8c2f-c5a8a5e2bd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 19])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "x = np.array([2,1,1])\n",
    "res = np.matmul(a,x)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c0081d3-e404-40cc-adbf-456bed9bd86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "a.append([1,2,3])\n",
    "a.append([4,5,6])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "954b0eec-1449-4e01-9590-456953546176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, numInputs):\n",
    "        #initialize the random weights and biases\n",
    "        self.numInputs = numInputs\n",
    "        self.weights = np.random.randn(numInputs)\n",
    "        self.bias = np.random.randn(1)\n",
    "    def __repr__(self):\n",
    "        return f\"Num Inputs : {self.numInputs}, weights : {self.weights}, bias : {self.bias}\"\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, numNeurons, numNeuronsLastLayer):\n",
    "        #initialize the random weights and biases\n",
    "        self.numNeuronsLastLayer = numNeuronsLastLayer\n",
    "        self.numNeurons = numNeurons\n",
    "        self.neurons = []\n",
    "        for i in range (numNeurons):\n",
    "            self.neurons.append(Neuron(numNeuronsLastLayer))\n",
    "    def __repr__(self):\n",
    "        return f\"Num neurons : {self.numNeurons}, num Inputs to each neuron : {self.numNeuronsLastLayer}\"\n",
    "\n",
    "class MLP:   # think of representing the mlp as just the weights matrix (think of it in 3d, where each slice holds the weights \n",
    "             # of a layer(2d matrix) in which each row holds the weights into the nth neuron) and the bias matrix (each row holds a layer's biases\n",
    "             # such that each cell holds the nth neuron's bias\n",
    "             # the full mlp can also be represented as one big matrix(3d) ofc such that each layer (a slice of the 2d matrix) has rows \n",
    "             # neurons, each neuron has its weights as columns and the last column will hold its bias  \n",
    "    def __init__(self, numNeuronsEachLayer, numFirstInputs):\n",
    "        self.numFirstInputs = numFirstInputs\n",
    "        self.numLayers = len(numNeuronsEachLayer)\n",
    "        self.numNeuronsEachLayer = numNeuronsEachLayer\n",
    "        self.layers = []\n",
    "        for i in range (self.numLayers):\n",
    "            if i ==0:\n",
    "                self.layers.append(Layer(numNeuronsEachLayer[0], numFirstInputs))\n",
    "            else:\n",
    "                self.layers.append(Layer(numNeuronsEachLayer[i], numNeuronsEachLayer[i-1]))\n",
    "    def __repr__(self):\n",
    "        string = f\"Num Layers : {self.numLayers}, num neurons in each layer :\"\n",
    "        for layer in self.layers:\n",
    "            string += f\"\\n{layer}\"\n",
    "        return string  \n",
    "    def feedForward(self, inputs):\n",
    "        if len(inputs) == self.numFirstInputs:\n",
    "            inputs = np.array(inputs)\n",
    "            inputs = inputs.reshape((3,1))\n",
    "            for i in range(self.numLayers):\n",
    "                WeightsMatrix = []\n",
    "                biasesVector = []\n",
    "                for neuron in self.layers[i].neurons:\n",
    "                    WeightsMatrix.append(neuron.weights)\n",
    "                    biasesVector.append(neuron.bias)\n",
    "                WeightsMatrix = np.array(WeightsMatrix)\n",
    "                biasesVector = np.array(biasesVector)\n",
    "                # print(f\"weights : {WeightsMatrix.shape}\") #in the first loop, this should be (2,3)\n",
    "                # print(f\"inputs : {inputs.shape}\") #in the first loop, this should be (3,1)\n",
    "                # print(f\"biases : {biasesVector.shape}\") #in the first .. (2,1)\n",
    "                if i == self.numLayers -1 : #last layer\n",
    "                    return (np.matmul(WeightsMatrix, inputs) + biasesVector).item()\n",
    "                \n",
    "                inputs = relU(np.matmul(WeightsMatrix, inputs) + biasesVector) #this is the output vector of this layer and the input to the next\n",
    "                ln = len(inputs)\n",
    "                inputs = np.array(inputs).reshape((ln,1))\n",
    "                #print(inputs.shape)\n",
    "            #prediction = inputs #the prediction is the last 'inputs' calculated in the loop \n",
    "    def print_params(self):\n",
    "        count_neurons = 0\n",
    "        for layer in self.layers:\n",
    "            for neuron in layer.neurons:\n",
    "                count_neurons += 1\n",
    "                print(f\"the neuron's weights : {neuron.weights}, its bias : {neuron.bias}\")\n",
    "        print(f\"the total number of neurons is : {count_neurons}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a2c16b58-83cd-4dd5-872f-0d733e624209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the neuron's weights : [-0.5201586   0.38001414 -0.18221631], its bias : [-0.21733953]\n",
      "the neuron's weights : [ 0.33328007 -0.43107222 -1.6639359 ], its bias : [0.08017629]\n",
      "the neuron's weights : [ 0.7076998  -0.04243862], its bias : [0.0322067]\n",
      "the neuron's weights : [-0.89911376 -0.22251006], its bias : [-0.85288834]\n",
      "the neuron's weights : [-0.27358298 -0.79220606], its bias : [1.45982235]\n",
      "the total number of neurons is : 5\n"
     ]
    }
   ],
   "source": [
    "first_mlp = MLP([2,2,1],3)\n",
    "first_mlp.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1c2fde0e-3cd9-4ea4-b750-087b2fd111f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.22152358]]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([3.65242382, 0.]).reshape((2,1))\n",
    "a = np.array([ -0.72341732,  0.51790669]).reshape((1,2))\n",
    "biases = np.array([-1.57929693]).reshape((1,1))\n",
    "print(np.matmul(a,inputs) + biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8893f9a7-defa-444f-934b-5a7ec755f138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4598223468436633"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_mlp.feedForward([2,1,-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "147b70a1-6290-4dd7-a36f-2c747af7ab3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.63617507164974, 0.0, 4.825545936078129, 32.2124572011748, 0.6333543503080545, 0.0, 0.0, 0.8879144003930031, 0.0, 0.8697516665611187]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in range(10):\n",
    "    first_mlp = MLP([2,2,1],3)\n",
    "    predictions.append(first_mlp.feedForward([2,1,-3]))\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a02720-d85d-4668-b2a7-08c467e8e9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4311a6ce-e6fe-41e3-9937-ec86e5411ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x1, x2, x3] = [2,1,-3]\n",
    "inputs = [x1, x2, x3]\n",
    "inputs = np.array(inputs)\n",
    "numInputs = len(inputs)\n",
    "numNeuronsEachLayer = [numInputs, 2, 2, 1]\n",
    "neurons = {\n",
    "'neuron1' : {'Layer' : 1, 'bias' : np.random.randn(1), 'W': np.random.randn(numNeuronsEachLayer[0])},\n",
    "'neuron2' : {'Layer' : 1, 'bias' : np.random.randn(1) , 'W': np.random.randn(numNeuronsEachLayer[0])},\n",
    "'neuron3' : {'Layer' : 2, 'bias' : np.random.randn(1) , 'W': np.random.randn(numNeuronsEachLayer[1])},\n",
    "'neuron4' : {'Layer' : 2, 'bias' : np.random.randn(1) , 'W': np.random.randn(numNeuronsEachLayer[1])},\n",
    "'neuron5' : {'Layer' : 3, 'bias' : np.random.randn(1) , 'W': np.random.randn(numNeuronsEachLayer[2])}\n",
    "}\n",
    "numLayers = len(numNeuronsEachLayer)\n",
    "target = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c46c26fd-d4d5-47fd-a8eb-be7a25e30a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 4, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numConnectionsEachLayer = []\n",
    "for i in range(numLayers -1):\n",
    "     numConnectionsEachLayer.append(numNeuronsEachLayer[i] * numNeuronsEachLayer[i+1])\n",
    "\n",
    "numConnectionsEachLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f734391b-006e-4a65-aac9-c21122b1012c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([-0.30257636, -0.76882194, -0.54812076,  0.57269727, -0.40026895,\n",
       "          0.09127235])],\n",
       " [array([ 0.78229834,  0.83179698, -1.65441878,  0.10237479])],\n",
       " [array([ 0.10814696, -1.72691368])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = [np.random.randn(numConnectionsEachLayer[0])]\n",
    "W2 = [np.random.randn(numConnectionsEachLayer[1])]\n",
    "W3 = [np.random.randn(numConnectionsEachLayer[2])]\n",
    "W1, W2, W3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab3a4f-008b-4a48-baa1-f55d6a86005d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
